#!/usr/bin/env python3
"""
PyTorchVideo Accelerator EfficientX3D ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

X3D_XS (fp32), X3D_XS (int8), X3D_S (fp32) ëª¨ë¸ ì§€ì›

ì‚¬ìš© ì˜ˆì‹œ:
# X3D-XS í•™ìŠµ (ëª¨ë°”ì¼ ìµœì í™”)
python train_efficient_x3d.py --data_root ./datasest --model_variant XS --batch_size 4 --epochs 50

# X3D-S í•™ìŠµ (ê· í˜•ì¡íŒ ì„±ëŠ¥)
python train_efficient_x3d.py --data_root ./datasest --model_variant S --batch_size 2 --epochs 50 --export_mobile_model --quantize_model
"""

import argparse
import os
import warnings
from pathlib import Path

import pytorch_lightning as pl
from pytorch_lightning.callbacks import (
    EarlyStopping,
    LearningRateMonitor,
    ModelCheckpoint,
    RichProgressBar,
)
from pytorch_lightning.loggers import TensorBoardLogger
import torch

from sign_language_datamodule import SignLanguageDataModule
from sign_language_model import SignLanguageClassifier

warnings.filterwarnings("ignore", category=UserWarning)


def get_model_config(variant: str):
    """ëª¨ë¸ ë³€í˜•ì— ë”°ë¥¸ ì„¤ì • ë°˜í™˜"""
    configs = {
        "XS": {
            "model_name": "efficient_x3d_xs",
            "input_size": (1, 3, 4, 160, 160),
            "clip_duration": 1.0,  # 4 frames at 4 FPS
            "num_frames": 4,
            "crop_size": 160,
            "batch_size": 8,
            "learning_rate": 1e-3,
            "description": "ëª¨ë°”ì¼ ìµœì í™” - ë¹ ë¥¸ ì¶”ë¡ , ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"
        },
        "S": {
            "model_name": "efficient_x3d_s", 
            "input_size": (1, 3, 13, 160, 160),
            "clip_duration": 2.17,  # 13 frames at 6 FPS
            "num_frames": 13,
            "crop_size": 160,
            "batch_size": 4,
            "learning_rate": 8e-4,
            "description": "ê· í˜•ì¡íŒ ì„±ëŠ¥ - ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì˜ ë°¸ëŸ°ìŠ¤"
        }
    }
    return configs.get(variant, configs["XS"])


def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="EfficientX3D ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
    
    # ë°ì´í„° ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--data_root", type=str, required=True,
                       help="ë°ì´í„° ë£¨íŠ¸ í´ë” ê²½ë¡œ (videoì™€ label í´ë” í¬í•¨)")
    parser.add_argument("--train_data_root", type=str, default=None,
                       help="í•™ìŠµ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    parser.add_argument("--val_data_root", type=str, default=None,
                       help="ê²€ì¦ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    parser.add_argument("--test_data_root", type=str, default=None,
                       help="í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    
    # ëª¨ë¸ ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--model_variant", type=str, default="XS",
                       choices=["XS", "S"],
                       help="EfficientX3D ëª¨ë¸ ë³€í˜• (XS: ëª¨ë°”ì¼ ìµœì í™”, S: ê· í˜•)")
    parser.add_argument("--pretrained", action="store_true", default=True,
                       help="ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
    parser.add_argument("--freeze_backbone", action="store_true",
                       help="ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê³ ì •")
    parser.add_argument("--dropout_rate", type=float, default=0.5,
                       help="ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨")
    
    # í•™ìŠµ ê´€ë ¨ ì¸ìˆ˜ (ëª¨ë¸ ì„¤ì •ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
    parser.add_argument("--batch_size", type=int, default=None,
                       help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: ëª¨ë¸ ì„¤ì •ê°’)")
    parser.add_argument("--learning_rate", type=float, default=None,
                       help="í•™ìŠµë¥  (ê¸°ë³¸ê°’: ëª¨ë¸ ì„¤ì •ê°’)")
    parser.add_argument("--epochs", type=int, default=50,
                       help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--optimizer", type=str, default="adam",
                       choices=["adam", "sgd"],
                       help="ì˜µí‹°ë§ˆì´ì €")
    parser.add_argument("--scheduler", type=str, default="cosine",
                       choices=["cosine", "step", "none"],
                       help="í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬")
    parser.add_argument("--weight_decay", type=float, default=1e-4,
                       help="ê°€ì¤‘ì¹˜ ê°ì‡ ")
    parser.add_argument("--label_smoothing", type=float, default=0.1,
                       help="ë¼ë²¨ ìŠ¤ë¬´ë”©")
    
    # ë°ì´í„° ë¡œë” ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--num_workers", type=int, default=4,
                       help="ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜")
    
    # í•™ìŠµ í™˜ê²½ ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--gpus", type=int, default=1,
                       help="ì‚¬ìš©í•  GPU ìˆ˜")
    parser.add_argument("--accelerator", type=str, default="auto",
                       help="ê°€ì†ê¸° íƒ€ì…")
    parser.add_argument("--precision", type=str, default="16-mixed",
                       choices=["16-mixed", "32", "bf16-mixed"],
                       help="ì—°ì‚° ì •ë°€ë„")
    parser.add_argument("--seed", type=int, default=42,
                       help="ëœë¤ ì‹œë“œ")
    
    # ì²´í¬í¬ì¸íŠ¸ ë° ë¡œê¹… ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--output_dir", type=str, default="./outputs",
                       help="ì¶œë ¥ í´ë” ê²½ë¡œ")
    parser.add_argument("--experiment_name", type=str, default=None,
                       help="ì‹¤í—˜ ì´ë¦„ (ê¸°ë³¸ê°’: efficient_x3d_{variant})")
    parser.add_argument("--resume_from_checkpoint", type=str, default=None,
                       help="ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ")
    
    # EfficientX3D ì „ìš© ì˜µì…˜
    parser.add_argument("--enable_efficient_deployment", action="store_true", default=True,
                       help="íš¨ìœ¨ì  ë°°í¬ ëª¨ë“œ í™œì„±í™”")
    parser.add_argument("--export_mobile_model", action="store_true",
                       help="ëª¨ë°”ì¼ ë°°í¬ìš© ëª¨ë¸ ë‚´ë³´ë‚´ê¸°")
    parser.add_argument("--quantize_model", action="store_true",
                       help="INT8 ì–‘ìí™” ì ìš©")
    parser.add_argument("--mobile_model_path", type=str, default=None,
                       help="ëª¨ë°”ì¼ ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: ìë™ ìƒì„±)")
    
    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument("--test_only", action="store_true",
                       help="í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰")
    parser.add_argument("--fast_dev_run", action="store_true",
                       help="ë¹ ë¥¸ ê°œë°œ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)")
    
    return parser.parse_args()


def setup_callbacks(output_dir: str, monitor_metric: str = "val/accuracy"):
    """ì½œë°± ì„¤ì •"""
    callbacks = [
        # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
        ModelCheckpoint(
            dirpath=os.path.join(output_dir, "checkpoints"),
            filename="best-{epoch:02d}-{val_accuracy:.4f}",
            monitor=monitor_metric,
            mode="max",
            save_top_k=3,
            save_last=True,
            verbose=True,
        ),
        
        # ì¡°ê¸° ì¢…ë£Œ
        EarlyStopping(
            monitor=monitor_metric,
            mode="max",
            patience=15,  # EfficientX3DëŠ” ë” ê¸´ patience ì‚¬ìš©
            verbose=True,
        ),
        
        # í•™ìŠµë¥  ëª¨ë‹ˆí„°ë§
        LearningRateMonitor(logging_interval="epoch"),
        
        # ì§„í–‰ë¥  í‘œì‹œ
        RichProgressBar(),
    ]
    
    return callbacks


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_config = get_model_config(args.model_variant)
    
    # ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ
    batch_size = args.batch_size or model_config["batch_size"]
    learning_rate = args.learning_rate or model_config["learning_rate"]
    clip_duration = model_config["clip_duration"]
    num_frames = model_config["num_frames"]
    crop_size = model_config["crop_size"]
    efficient_input_size = model_config["input_size"]
    
    # ì‹¤í—˜ ì´ë¦„ ì„¤ì •
    experiment_name = args.experiment_name or f"efficient_x3d_{args.model_variant.lower()}"
    
    # ëª¨ë°”ì¼ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    mobile_model_path = args.mobile_model_path or f"./mobile_x3d_{args.model_variant.lower()}.pt"
    
    # ì‹œë“œ ì„¤ì •
    pl.seed_everything(args.seed, workers=True)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(args.output_dir) / experiment_name
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸš€ EfficientX3D-{args.model_variant} ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print(f"ğŸ“ ëª¨ë¸ ì„¤ëª…: {model_config['description']}")
    print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {args.data_root}")
    print(f"ğŸ¯ ëª¨ë¸: {model_config['model_name']}")
    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"ğŸ”„ ì—í¬í¬: {args.epochs}")
    print(f"ğŸ“ ì…ë ¥ í¬ê¸°: {efficient_input_size}")
    print(f"ğŸ¬ í´ë¦½ ê¸¸ì´: {clip_duration}ì´ˆ ({num_frames} í”„ë ˆì„)")
    print(f"ğŸ’¾ ì¶œë ¥ ê²½ë¡œ: {output_dir}")
    
    # ë°ì´í„° ëª¨ë“ˆ ì„¤ì •
    print("\nğŸ“‹ ë°ì´í„° ëª¨ë“ˆ ì„¤ì • ì¤‘...")
    datamodule = SignLanguageDataModule(
        data_root=args.data_root,
        train_data_root=args.train_data_root,
        val_data_root=args.val_data_root,
        test_data_root=args.test_data_root,
        batch_size=batch_size,
        num_workers=args.num_workers,
        clip_duration=clip_duration,
        num_frames=num_frames,
        crop_size=crop_size,
    )
    
    # ë°ì´í„° ì •ë³´ í™•ì¸
    datamodule.setup("fit")
    num_classes = datamodule.num_classes
    class_names = list(datamodule.class_to_idx.keys())
    
    print(f"âœ… í´ë˜ìŠ¤ ê°œìˆ˜: {num_classes}")
    print(f"ğŸ“ í´ë˜ìŠ¤ ëª©ë¡: {class_names}")
    
    # ëª¨ë¸ ì„¤ì •
    print(f"\nğŸ¤– EfficientX3D-{args.model_variant} ëª¨ë¸ ì„¤ì • ì¤‘...")
    model = SignLanguageClassifier(
        num_classes=num_classes,
        model_name=model_config["model_name"],
        learning_rate=learning_rate,
        optimizer=args.optimizer,
        scheduler=args.scheduler,
        pretrained=args.pretrained,
        freeze_backbone=args.freeze_backbone,
        dropout_rate=args.dropout_rate,
        label_smoothing=args.label_smoothing,
        weight_decay=args.weight_decay,
        enable_efficient_deployment=args.enable_efficient_deployment,
        efficient_input_size=efficient_input_size,
    )
    
    # ë¡œê±° ì„¤ì •
    logger = TensorBoardLogger(
        save_dir=output_dir,
        name="tensorboard_logs",
        version=None,
    )
    
    # ì½œë°± ì„¤ì •
    callbacks = setup_callbacks(output_dir)
    
    # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator=args.accelerator,
        devices=args.gpus,
        precision=args.precision,
        logger=logger,
        callbacks=callbacks,
        fast_dev_run=args.fast_dev_run,
        deterministic=True,
        enable_checkpointing=True,
        enable_progress_bar=True,
        enable_model_summary=True,
    )
    
    # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“ˆ ëª¨ë¸ ì •ë³´:")
    print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    print(f"   - ëª¨ë¸ í¬ê¸°: ~3.8M íŒŒë¼ë¯¸í„°")
    
    if args.test_only:
        # í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        if args.resume_from_checkpoint:
            print(f"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {args.resume_from_checkpoint}")
            model = SignLanguageClassifier.load_from_checkpoint(args.resume_from_checkpoint)
        trainer.test(model, datamodule=datamodule)
    else:
        # í•™ìŠµ ìˆ˜í–‰
        print("\nğŸƒ í•™ìŠµ ì‹œì‘!")
        trainer.fit(
            model,
            datamodule=datamodule,
            ckpt_path=args.resume_from_checkpoint,
        )
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        print("\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰")
        trainer.test(datamodule=datamodule, ckpt_path="best")
        
        # ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
        if args.export_mobile_model:
            print("\nğŸ“± ëª¨ë°”ì¼ ë°°í¬ìš© ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì¤‘...")
            try:
                # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                best_checkpoint = None
                checkpoint_dir = output_dir / "checkpoints"
                if checkpoint_dir.exists():
                    checkpoints = list(checkpoint_dir.glob("best-*.ckpt"))
                    if checkpoints:
                        best_checkpoint = str(checkpoints[0])
                
                if best_checkpoint:
                    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ
                    mobile_model = SignLanguageClassifier.load_from_checkpoint(
                        best_checkpoint,
                        enable_efficient_deployment=True,
                        efficient_input_size=efficient_input_size,
                    )
                    
                    # ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
                    mobile_model.export_to_mobile(
                        mobile_model_path, 
                        quantize=args.quantize_model
                    )
                    
                    print(f"âœ… ëª¨ë°”ì¼ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {mobile_model_path}")
                else:
                    print("âš ï¸ ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"âŒ ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"\nâœ… ì™„ë£Œ! ê²°ê³¼ëŠ” {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š TensorBoard ë¡œê·¸: tensorboard --logdir {output_dir}/tensorboard_logs")
    
    # ì„±ëŠ¥ ë° ì‚¬ìš© ê°€ì´ë“œ
    print(f"\nğŸ¯ EfficientX3D-{args.model_variant} ì„±ëŠ¥ ì •ë³´:")
    if args.model_variant == "XS":
        print(f"   ğŸ“Š Kinetics-400 ì •í™•ë„: ~68.5% (top-1), ~88.0% (top-5)")
        print(f"   âš¡ ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: ~233ms (fp32), ~165ms (int8) on Samsung S8")
        print(f"   ğŸ’¾ ëª¨ë¸ í¬ê¸°: ~3.8M íŒŒë¼ë¯¸í„°, ~15MB")
        print(f"   ğŸ¯ ìš©ë„: ì‹¤ì‹œê°„ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜, IoT ë””ë°”ì´ìŠ¤")
    elif args.model_variant == "S":
        print(f"   ğŸ“Š Kinetics-400 ì •í™•ë„: ~73.0% (top-1), ~90.6% (top-5)")
        print(f"   âš¡ ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: ~764ms (fp32) on Samsung S8")
        print(f"   ğŸ’¾ ëª¨ë¸ í¬ê¸°: ~3.8M íŒŒë¼ë¯¸í„°, ~15MB")
        print(f"   ğŸ¯ ìš©ë„: ê· í˜•ì¡íŒ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜")
    
    print(f"\nğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ:")
    print(f"   ğŸ”§ ì¶”ë¡ : inference.py --checkpoint {output_dir}/checkpoints/best-*.ckpt")
    print(f"   ğŸ“± ëª¨ë°”ì¼: {mobile_model_path} íŒŒì¼ì„ ëª¨ë°”ì¼ ì•±ì— í†µí•©")
    print(f"   âš¡ ìµœì í™”: ì¶”ë¡  ì‹œ ë°°í¬ ëª¨ë“œ ìë™ í™œì„±í™”")
    
    if args.quantize_model and args.export_mobile_model:
        print(f"   ğŸ—œï¸ ì–‘ìí™”: INT8 ëª¨ë¸ë¡œ ~75% í¬ê¸° ê°ì†Œ, ~30% ì†ë„ í–¥ìƒ")


if __name__ == "__main__":
    main() 