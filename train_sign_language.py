#!/usr/bin/env python3
"""
ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ì˜ˆì‹œ:
python train_sign_language.py --data_root ./datasest --model_name slow_r50 --batch_size 4 --epochs 50
"""

import argparse
import os
import warnings
from pathlib import Path

import pytorch_lightning as pl
from pytorch_lightning.callbacks import (
    EarlyStopping,
    LearningRateMonitor,
    ModelCheckpoint,
    RichProgressBar,
)
from pytorch_lightning.loggers import TensorBoardLogger
import torch

from sign_language_datamodule import SignLanguageDataModule
from sign_language_model import SignLanguageClassifier

# PyTorchVideo ê´€ë ¨ ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning)


def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
    
    # ë°ì´í„° ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--data_root", type=str, required=True,
                       help="ë°ì´í„° ë£¨íŠ¸ í´ë” ê²½ë¡œ (videoì™€ label í´ë” í¬í•¨)")
    parser.add_argument("--train_data_root", type=str, default=None,
                       help="í•™ìŠµ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    parser.add_argument("--val_data_root", type=str, default=None,
                       help="ê²€ì¦ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    parser.add_argument("--test_data_root", type=str, default=None,
                       help="í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸ê°’: data_root)")
    
    # ëª¨ë¸ ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--model_name", type=str, default="slow_r50",
                       choices=["slow_r50", "x3d_s", "x3d_m", "mvit_base_16x4", "efficient_x3d_xs", "efficient_x3d_s"],
                       help="ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„")
    parser.add_argument("--pretrained", action="store_true", default=True,
                       help="ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
    parser.add_argument("--freeze_backbone", action="store_true",
                       help="ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê³ ì •")
    parser.add_argument("--dropout_rate", type=float, default=0.5,
                       help="ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨")
    
    # í•™ìŠµ ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--batch_size", type=int, default=8,
                       help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning_rate", type=float, default=1e-3,
                       help="í•™ìŠµë¥ ")
    parser.add_argument("--epochs", type=int, default=50,
                       help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--optimizer", type=str, default="adam",
                       choices=["adam", "sgd"],
                       help="ì˜µí‹°ë§ˆì´ì €")
    parser.add_argument("--scheduler", type=str, default="cosine",
                       choices=["cosine", "step", "none"],
                       help="í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬")
    parser.add_argument("--weight_decay", type=float, default=1e-4,
                       help="ê°€ì¤‘ì¹˜ ê°ì‡ ")
    parser.add_argument("--label_smoothing", type=float, default=0.0,
                       help="ë¼ë²¨ ìŠ¤ë¬´ë”©")
    
    # ë°ì´í„° ë¡œë” ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--num_workers", type=int, default=4,
                       help="ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜")
    parser.add_argument("--clip_duration", type=float, default=2.0,
                       help="ë¹„ë””ì˜¤ í´ë¦½ ì§€ì† ì‹œê°„ (ì´ˆ)")
    parser.add_argument("--num_frames", type=int, default=16,
                       help="ìƒ˜í”Œë§í•  í”„ë ˆì„ ìˆ˜")
    parser.add_argument("--crop_size", type=int, default=224,
                       help="ì´ë¯¸ì§€ í¬ë¡­ í¬ê¸°")
    
    # í•™ìŠµ í™˜ê²½ ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--gpus", type=int, default=1,
                       help="ì‚¬ìš©í•  GPU ìˆ˜")
    parser.add_argument("--accelerator", type=str, default="auto",
                       help="ê°€ì†ê¸° íƒ€ì…")
    parser.add_argument("--precision", type=str, default="16-mixed",
                       choices=["16-mixed", "32", "bf16-mixed"],
                       help="ì—°ì‚° ì •ë°€ë„")
    parser.add_argument("--seed", type=int, default=42,
                       help="ëœë¤ ì‹œë“œ")
    
    # ì²´í¬í¬ì¸íŠ¸ ë° ë¡œê¹… ê´€ë ¨ ì¸ìˆ˜
    parser.add_argument("--output_dir", type=str, default="./outputs",
                       help="ì¶œë ¥ í´ë” ê²½ë¡œ")
    parser.add_argument("--experiment_name", type=str, default="sign_language_classification",
                       help="ì‹¤í—˜ ì´ë¦„")
    parser.add_argument("--resume_from_checkpoint", type=str, default=None,
                       help="ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ")
    
    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument("--test_only", action="store_true",
                       help="í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰")
    parser.add_argument("--fast_dev_run", action="store_true",
                       help="ë¹ ë¥¸ ê°œë°œ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)")
    
    # Efficient ëª¨ë¸ ê´€ë ¨ ì˜µì…˜
    parser.add_argument("--enable_efficient_deployment", action="store_true",
                       help="íš¨ìœ¨ì  ë°°í¬ ëª¨ë“œ í™œì„±í™” (efficient ëª¨ë¸ ì „ìš©)")
    parser.add_argument("--export_mobile_model", action="store_true",
                       help="ëª¨ë°”ì¼ ë°°í¬ìš© ëª¨ë¸ ë‚´ë³´ë‚´ê¸°")
    parser.add_argument("--quantize_model", action="store_true",
                       help="INT8 ì–‘ìí™” ì ìš© (ëª¨ë°”ì¼ ë‚´ë³´ë‚´ê¸° ì‹œ)")
    parser.add_argument("--mobile_model_path", type=str, default="./mobile_model.pt",
                       help="ëª¨ë°”ì¼ ëª¨ë¸ ì €ì¥ ê²½ë¡œ")
    
    return parser.parse_args()


def setup_callbacks(output_dir: str, monitor_metric: str = "val/accuracy"):
    """ì½œë°± ì„¤ì •"""
    callbacks = [
        # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
        ModelCheckpoint(
            dirpath=os.path.join(output_dir, "checkpoints"),
            filename="best-{epoch:02d}-{val_accuracy:.4f}",
            monitor=monitor_metric,
            mode="max",
            save_top_k=3,
            save_last=True,
            verbose=True,
        ),
        
        # ì¡°ê¸° ì¢…ë£Œ
        EarlyStopping(
            monitor=monitor_metric,
            mode="max",
            patience=10,
            verbose=True,
        ),
        
        # í•™ìŠµë¥  ëª¨ë‹ˆí„°ë§
        LearningRateMonitor(logging_interval="epoch"),
        
        # ì§„í–‰ë¥  í‘œì‹œ
        RichProgressBar(),
    ]
    
    return callbacks


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ì‹œë“œ ì„¤ì •
    pl.seed_everything(args.seed, workers=True)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(args.output_dir) / args.experiment_name
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸš€ ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {args.data_root}")
    print(f"ğŸ¯ ëª¨ë¸: {args.model_name}")
    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"ğŸ”„ ì—í¬í¬: {args.epochs}")
    print(f"ğŸ’¾ ì¶œë ¥ ê²½ë¡œ: {output_dir}")
    
    # ë°ì´í„° ëª¨ë“ˆ ì„¤ì •
    print("\nğŸ“‹ ë°ì´í„° ëª¨ë“ˆ ì„¤ì • ì¤‘...")
    datamodule = SignLanguageDataModule(
        data_root=args.data_root,
        train_data_root=args.train_data_root,
        val_data_root=args.val_data_root,
        test_data_root=args.test_data_root,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        clip_duration=args.clip_duration,
        num_frames=args.num_frames,
        crop_size=args.crop_size,
    )
    
    # ë°ì´í„° ì •ë³´ í™•ì¸ì„ ìœ„í•´ setup í˜¸ì¶œ
    datamodule.setup("fit")
    num_classes = datamodule.num_classes
    class_names = list(datamodule.class_to_idx.keys())
    
    print(f"âœ… í´ë˜ìŠ¤ ê°œìˆ˜: {num_classes}")
    print(f"ğŸ“ í´ë˜ìŠ¤ ëª©ë¡: {class_names}")
    
    # ëª¨ë¸ ì„¤ì •
    print(f"\nğŸ¤– ëª¨ë¸ ì„¤ì • ì¤‘... ({args.model_name})")
    
    # Efficient ëª¨ë¸ì„ ìœ„í•œ ì…ë ¥ í¬ê¸° ê³„ì‚°
    efficient_input_size = (args.batch_size, 3, args.num_frames, args.crop_size, args.crop_size)
    if args.model_name.startswith("efficient_x3d_xs"):
        efficient_input_size = (1, 3, 4, 160, 160)  # X3D-XS ê¶Œì¥ í¬ê¸°
    elif args.model_name.startswith("efficient_x3d_s"):
        efficient_input_size = (1, 3, 13, 160, 160)  # X3D-S ê¶Œì¥ í¬ê¸°
    
    model = SignLanguageClassifier(
        num_classes=num_classes,
        model_name=args.model_name,
        learning_rate=args.learning_rate,
        optimizer=args.optimizer,
        scheduler=args.scheduler,
        pretrained=args.pretrained,
        freeze_backbone=args.freeze_backbone,
        dropout_rate=args.dropout_rate,
        label_smoothing=args.label_smoothing,
        weight_decay=args.weight_decay,
        enable_efficient_deployment=args.enable_efficient_deployment,
        efficient_input_size=efficient_input_size,
    )
    
    # ë¡œê±° ì„¤ì •
    logger = TensorBoardLogger(
        save_dir=output_dir,
        name="tensorboard_logs",
        version=None,
    )
    
    # ì½œë°± ì„¤ì •
    callbacks = setup_callbacks(output_dir)
    
    # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator=args.accelerator,
        devices=args.gpus,
        precision=args.precision,
        logger=logger,
        callbacks=callbacks,
        fast_dev_run=args.fast_dev_run,
        deterministic=True,
        enable_checkpointing=True,
        enable_progress_bar=True,
        enable_model_summary=True,
    )
    
    # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“ˆ ëª¨ë¸ ì •ë³´:")
    print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    if args.test_only:
        # í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        if args.resume_from_checkpoint:
            print(f"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {args.resume_from_checkpoint}")
            model = SignLanguageClassifier.load_from_checkpoint(args.resume_from_checkpoint)
        trainer.test(model, datamodule=datamodule)
    else:
        # í•™ìŠµ ìˆ˜í–‰
        print("\nğŸƒ í•™ìŠµ ì‹œì‘!")
        trainer.fit(
            model,
            datamodule=datamodule,
            ckpt_path=args.resume_from_checkpoint,
        )
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        print("\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰")
        trainer.test(datamodule=datamodule, ckpt_path="best")
        
        # ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (efficient ëª¨ë¸ì¸ ê²½ìš°)
        if args.export_mobile_model and args.model_name.startswith("efficient_"):
            print("\nğŸ“± ëª¨ë°”ì¼ ë°°í¬ìš© ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì¤‘...")
            try:
                # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                best_checkpoint = None
                checkpoint_dir = output_dir / "checkpoints"
                if checkpoint_dir.exists():
                    checkpoints = list(checkpoint_dir.glob("best-*.ckpt"))
                    if checkpoints:
                        best_checkpoint = str(checkpoints[0])
                
                if best_checkpoint:
                    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ
                    mobile_model = SignLanguageClassifier.load_from_checkpoint(
                        best_checkpoint,
                        enable_efficient_deployment=True,
                        efficient_input_size=efficient_input_size,
                    )
                    
                    # ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
                    mobile_model.export_to_mobile(
                        args.mobile_model_path, 
                        quantize=args.quantize_model
                    )
                    
                    print(f"âœ… ëª¨ë°”ì¼ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {args.mobile_model_path}")
                else:
                    print("âš ï¸ ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"âŒ ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"\nâœ… ì™„ë£Œ! ê²°ê³¼ëŠ” {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š TensorBoard ë¡œê·¸: tensorboard --logdir {output_dir}/tensorboard_logs")
    
    # Efficient ëª¨ë¸ ì‚¬ìš© íŒ ì œê³µ
    if args.model_name.startswith("efficient_"):
        print(f"\nğŸ’¡ Efficient ëª¨ë¸ ì‚¬ìš© íŒ:")
        print(f"   - ì¶”ë¡  ì‹œ --enable_efficient_deployment í”Œë˜ê·¸ ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ")
        print(f"   - ëª¨ë°”ì¼ ë°°í¬: --export_mobile_model --quantize_model í”Œë˜ê·¸ ì‚¬ìš©")
        print(f"   - ê¶Œì¥ ì…ë ¥ í¬ê¸°: {efficient_input_size}")
        if args.model_name == "efficient_x3d_xs":
            print(f"   - ì˜ˆìƒ ì„±ëŠ¥: ~68.5% top-1 ì •í™•ë„ (Kinetics-400 ê¸°ì¤€)")
            print(f"   - ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: ~233ms (fp32), ~165ms (int8) on Samsung S8")
        elif args.model_name == "efficient_x3d_s":
            print(f"   - ì˜ˆìƒ ì„±ëŠ¥: ~73.0% top-1 ì •í™•ë„ (Kinetics-400 ê¸°ì¤€)")
            print(f"   - ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: ~764ms (fp32) on Samsung S8")


if __name__ == "__main__":
    main() 