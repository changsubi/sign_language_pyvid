# ìˆ˜ì–´ ë¶„ë¥˜ (Sign Language Classification) í”„ë¡œì íŠ¸

PyTorchVideoë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìˆ˜ì–´ ë¹„ë””ì˜¤ ë¶„ë¥˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ìˆ˜ì–´ ë™ì‘ì„ ì¸ì‹í•˜ê³  ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ sign_language_dataset.py      # ìˆ˜ì–´ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
â”œâ”€â”€ sign_language_datamodule.py   # PyTorch Lightning ë°ì´í„° ëª¨ë“ˆ
â”œâ”€â”€ sign_language_model.py        # ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸
â”œâ”€â”€ train_sign_language.py        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ inference.py                  # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt              # í•„ìš” íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€â”€ README_sign_language.md       # í”„ë¡œì íŠ¸ ê°€ì´ë“œ
```

## ğŸ“Š ë°ì´í„° í˜•ì‹

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
your_data_root/
â”œâ”€â”€ video/
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.mp4
â”‚   â””â”€â”€ ...
â””â”€â”€ label/
    â”œâ”€â”€ video1_morpheme.json
    â”œâ”€â”€ video2_morpheme.json
    â””â”€â”€ ...
```

### ë¼ë²¨ JSON í˜•ì‹
```json
{
    "metaData": {
        "name": "video_name.mp4",
        "duration": 3.884,
        "url": "...",
        "exportedOn": "2020/12/10"
    },
    "data": [
        {
            "start": 1.879,
            "end": 3.236,
            "attributes": [
                {
                    "name": "ìˆ˜ì–´_ë‹¨ì–´ëª…"
                }
            ]
        }
    ]
}
```

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)
python -m venv sign_language_env
source sign_language_env/bin/activate  # Linux/Mac
# sign_language_env\Scripts\activate  # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. GPU ì„¤ì • (ì„ íƒì‚¬í•­)
CUDAê°€ ì„¤ì¹˜ëœ í™˜ê²½ì—ì„œ GPU ê°€ì†ì„ ì‚¬ìš©í•˜ë ¤ë©´:
```bash
# PyTorch GPU ë²„ì „ ì„¤ì¹˜ (CUDA ë²„ì „ì— ë§ê²Œ)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ¯ ì‚¬ìš© ë°©ë²•

### 1. ëª¨ë¸ í•™ìŠµ

#### ê¸°ë³¸ í•™ìŠµ
```bash
python train_sign_language.py \
    --data_root ./datasest \
    --model_name slow_r50 \
    --batch_size 4 \
    --epochs 50 \
    --learning_rate 1e-3
```

#### ê³ ê¸‰ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
```bash
python train_sign_language.py \
    --data_root ./your_data_root \
    --train_data_root ./train_data \
    --val_data_root ./val_data \
    --model_name x3d_m \
    --batch_size 8 \
    --epochs 100 \
    --learning_rate 5e-4 \
    --optimizer adam \
    --scheduler cosine \
    --dropout_rate 0.3 \
    --weight_decay 1e-4 \
    --gpus 1 \
    --precision 16-mixed \
    --output_dir ./experiments \
    --experiment_name my_sign_language_model
```

#### ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
- `slow_r50`: SlowFast ResNet-50 (ê¸°ë³¸ê°’)
- `x3d_s`: X3D-S (íš¨ìœ¨ì , ë¹ ë¦„)
- `x3d_m`: X3D-M (ê· í˜•)
- `mvit_base_16x4`: MViT-Base (íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜)
- `efficient_x3d_xs`: EfficientX3D-XS (ëª¨ë°”ì¼ ìµœì í™”, 3.8M íŒŒë¼ë¯¸í„°)
- `efficient_x3d_s`: EfficientX3D-S (ê· í˜•ì¡íŒ ëª¨ë°”ì¼ ëª¨ë¸)

### 2. ëª¨ë¸ ì¶”ë¡ 

#### ë‹¨ì¼ ë¹„ë””ì˜¤ ì¶”ë¡ 
```bash
python inference.py \
    --checkpoint ./outputs/sign_language_classification/checkpoints/best.ckpt \
    --video_path ./test_video.mp4 \
    --clip_duration 2.0 \
    --output_path ./result.json
```

#### ë‹¤ì¤‘ í´ë¦½ ì¶”ë¡ 
```bash
python inference.py \
    --checkpoint ./outputs/sign_language_classification/checkpoints/best.ckpt \
    --video_path ./test_video.mp4 \
    --multiple_clips \
    --stride 1.0 \
    --return_probabilities \
    --output_path ./results.json
```

### 3. í•™ìŠµ ëª¨ë‹ˆí„°ë§

TensorBoardë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```bash
tensorboard --logdir ./outputs/sign_language_classification/tensorboard_logs
```

## âš™ï¸ ì£¼ìš” ë§¤ê°œë³€ìˆ˜

### í•™ìŠµ ë§¤ê°œë³€ìˆ˜
- `--data_root`: ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ
- `--model_name`: ì‚¬ìš©í•  ëª¨ë¸ (slow_r50, x3d_s, x3d_m, mvit_base_16x4)
- `--batch_size`: ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
- `--learning_rate`: í•™ìŠµë¥ 
- `--epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜
- `--num_frames`: ë¹„ë””ì˜¤ì—ì„œ ìƒ˜í”Œë§í•  í”„ë ˆì„ ìˆ˜
- `--clip_duration`: ë¹„ë””ì˜¤ í´ë¦½ ê¸¸ì´ (ì´ˆ)

### ìµœì í™” ë§¤ê°œë³€ìˆ˜
- `--optimizer`: adam ë˜ëŠ” sgd
- `--scheduler`: cosine, step, ë˜ëŠ” none
- `--weight_decay`: ê°€ì¤‘ì¹˜ ê°ì‡ 
- `--dropout_rate`: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
- `--label_smoothing`: ë¼ë²¨ ìŠ¤ë¬´ë”©

### ë°ì´í„° ì²˜ë¦¬ ë§¤ê°œë³€ìˆ˜
- `--num_workers`: ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜
- `--crop_size`: ì´ë¯¸ì§€ í¬ë¡­ í¬ê¸°
- `--pin_memory`: GPU ë©”ëª¨ë¦¬ ê³ ì •

## ğŸ”§ ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€
`sign_language_model.py`ì˜ `_create_model` ë©”ì„œë“œì— ìƒˆë¡œìš´ ëª¨ë¸ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
elif model_name == "custom_model":
    model = your_custom_model(pretrained=pretrained)
    # ë¶„ë¥˜ í—¤ë“œ ìˆ˜ì •
    model.head = nn.Linear(model.head.in_features, num_classes)
```

### ë°ì´í„° ì¦ê°• ì»¤ìŠ¤í„°ë§ˆì´ì§•
`sign_language_datamodule.py`ì˜ ë³€í™˜ í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ë°ì´í„° ì¦ê°•ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ë°°ì¹˜ í¬ê¸° ì¡°ì •
- GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì„¸ìš”
- ì¼ë°˜ì ìœ¼ë¡œ 4-16 ì‚¬ì´ì˜ ê°’ì´ ì í•©í•©ë‹ˆë‹¤

### 2. í˜¼í•© ì •ë°€ë„ ì‚¬ìš©
```bash
--precision 16-mixed
```

### 3. ë°ì´í„° ë¡œë” ìµœì í™”
```bash
--num_workers 4  # CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì¡°ì •
--pin_memory    # GPU ì‚¬ìš© ì‹œ í™œì„±í™”
```

### 4. ëª¨ë¸ ì„ íƒ

## ğŸ“± ëª¨ë°”ì¼ ë°°í¬ (EfficientX3D)

### EfficientX3D ëª¨ë¸ íŠ¹ì§•
- **X3D-XS**: ëª¨ë°”ì¼ ìµœì í™” ëª¨ë¸ (3.8M íŒŒë¼ë¯¸í„°, ~15MB)
  - Kinetics-400 ì •í™•ë„: 68.5% (top-1), 88.0% (top-5)
  - ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: 233ms (fp32), 165ms (int8) on Samsung S8
  - ìš©ë„: ì‹¤ì‹œê°„ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜, IoT ë””ë°”ì´ìŠ¤

- **X3D-S**: ê· í˜•ì¡íŒ ëª¨ë°”ì¼ ëª¨ë¸ (3.8M íŒŒë¼ë¯¸í„°, ~15MB)
  - Kinetics-400 ì •í™•ë„: 73.0% (top-1), 90.6% (top-5)
  - ëª¨ë°”ì¼ ì§€ì—°ì‹œê°„: 764ms (fp32) on Samsung S8
  - ìš©ë„: ê· í˜•ì¡íŒ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜

### EfficientX3D ì „ìš© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

```bash
# X3D-XS í•™ìŠµ (ëª¨ë°”ì¼ ìµœì í™”)
python train_efficient_x3d.py \
    --data_root ./datasest \
    --model_variant XS \
    --batch_size 8 \
    --epochs 50 \
    --export_mobile_model

# X3D-S í•™ìŠµ (ê· í˜•ì¡íŒ ì„±ëŠ¥) + INT8 ì–‘ìí™”
python train_efficient_x3d.py \
    --data_root ./datasest \
    --model_variant S \
    --batch_size 4 \
    --epochs 50 \
    --export_mobile_model \
    --quantize_model
```

### ëª¨ë°”ì¼ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°

ê¸°ì¡´ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œë„ EfficientX3D ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥:
```bash
python train_sign_language.py \
    --data_root ./datasest \
    --model_name efficient_x3d_xs \
    --batch_size 8 \
    --epochs 50 \
    --enable_efficient_deployment \
    --export_mobile_model \
    --quantize_model \
    --mobile_model_path ./mobile_sign_language.pt
```

### ëª¨ë°”ì¼ ëª¨ë¸ ì‚¬ìš©
```python
import torch

# ëª¨ë°”ì¼ ëª¨ë¸ ë¡œë“œ
mobile_model = torch.jit.load("./mobile_sign_language.pt")
mobile_model.eval()

# ì¶”ë¡ 
with torch.no_grad():
    output = mobile_model(input_tensor)
```

### 4. ëª¨ë¸ ì„ íƒ
- **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘**: `x3d_s`
- **ê· í˜•ì¡íŒ ì„±ëŠ¥**: `slow_r50` ë˜ëŠ” `x3d_m`
- **ìµœê³  ì •í™•ë„**: `mvit_base_16x4`

## ğŸš¨ ë¬¸ì œ í•´ê²°

### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--batch_size 2

# í˜¼í•© ì •ë°€ë„ ì‚¬ìš©
--precision 16-mixed

# í”„ë ˆì„ ìˆ˜ ì¤„ì´ê¸°
--num_frames 8
```

### 2. ë°ì´í„° ë¡œë”© ëŠë¦¼
```bash
# ì›Œì»¤ ìˆ˜ ëŠ˜ë¦¬ê¸°
--num_workers 8

# ë©”ëª¨ë¦¬ ê³ ì • í™œì„±í™”
--pin_memory
```

### 3. í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ
```bash
# í•™ìŠµë¥  ì¡°ì •
--learning_rate 1e-4

# ë¼ë²¨ ìŠ¤ë¬´ë”© ì¶”ê°€
--label_smoothing 0.1

# ê°€ì¤‘ì¹˜ ê°ì‡  ì¡°ì •
--weight_decay 1e-3
```

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### í•™ìŠµ ë¡œê·¸ ì˜ˆì‹œ
```
ğŸš€ ìˆ˜ì–´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘
ğŸ“ ë°ì´í„° ê²½ë¡œ: ./datasest
ğŸ¯ ëª¨ë¸: slow_r50
ğŸ“Š ë°°ì¹˜ í¬ê¸°: 4
ğŸ”„ ì—í¬í¬: 50

ğŸ“‹ ë°ì´í„° ëª¨ë“ˆ ì„¤ì • ì¤‘...
Training dataset: 20 videos
Validation dataset: 20 videos
âœ… í´ë˜ìŠ¤ ê°œìˆ˜: 5
ğŸ“ í´ë˜ìŠ¤ ëª©ë¡: ['ì™¼ìª½', 'ì˜¤ë¥¸ìª½', 'ìœ„', 'ì•„ë˜', 'ì¤‘ì•™']

ğŸ¤– ëª¨ë¸ ì„¤ì • ì¤‘... (slow_r50)
ğŸ“ˆ ëª¨ë¸ ì •ë³´:
   - íŒŒë¼ë¯¸í„° ìˆ˜: 31,234,567
   - í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: 2,048

ğŸƒ í•™ìŠµ ì‹œì‘!
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:45<00:00,  9.12s/it, loss=1.23, v_num=0, train/accuracy=0.400]
...
```

### ì¶”ë¡  ê²°ê³¼ ì˜ˆì‹œ
```json
{
  "video_path": "./test_video.mp4",
  "start_time": 0.0,
  "end_time": 2.0,
  "predicted_class_idx": 0,
  "predicted_class_name": "ì™¼ìª½",
  "confidence": 0.8765,
  "clip_duration": 2.0
}
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [PyTorchVideo ê³µì‹ ë¬¸ì„œ](https://pytorchvideo.readthedocs.io/)
- [PyTorch Lightning ë¬¸ì„œ](https://lightning.ai/docs/pytorch/stable/)
- [ë¹„ë””ì˜¤ ë¶„ë¥˜ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](https://paperswithcode.com/task/video-classification)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. ì´ìŠˆ ë¦¬í¬íŠ¸
2. ê¸°ëŠ¥ ì œì•ˆ
3. ì½”ë“œ ê°œì„ 
4. ë¬¸ì„œ ì—…ë°ì´íŠ¸

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. 