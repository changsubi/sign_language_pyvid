#!/usr/bin/env python3
"""
ìˆ˜ì–´ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ë°ì´í„°ì…‹ ë¡œë”©, ëª¨ë¸ ìƒì„±, ë‹¨ì¼ ë°°ì¹˜ ìˆœì „íŒŒë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
ì‹¤ì œ í•™ìŠµ ì „ì— ì½”ë“œê°€ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ìš©ë„ì…ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
python quick_test.py --data_root ./datasest
"""

import argparse
import warnings
from pathlib import Path

import torch
import pytorch_lightning as pl

from sign_language_datamodule import SignLanguageDataModule
from sign_language_model import SignLanguageClassifier

warnings.filterwarnings("ignore", category=UserWarning)


def test_datamodule(data_root: str, batch_size: int = 2):
    """ë°ì´í„° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë°ì´í„° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        # ë°ì´í„° ëª¨ë“ˆ ìƒì„±
        datamodule = SignLanguageDataModule(
            data_root=data_root,
            batch_size=batch_size,
            num_workers=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
            clip_duration=2.0,
            num_frames=8,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” í”„ë ˆì„ ìˆ˜ ì¤„ì„
            crop_size=224,
        )
        
        # ë°ì´í„° ì„¤ì •
        datamodule.setup("fit")
        
        print(f"   âœ… í´ë˜ìŠ¤ ê°œìˆ˜: {datamodule.num_classes}")
        print(f"   âœ… í´ë˜ìŠ¤ ëª©ë¡: {list(datamodule.class_to_idx.keys())}")
        print(f"   âœ… í•™ìŠµ ë°ì´í„°: {len(datamodule.train_dataset)} videos")
        print(f"   âœ… ê²€ì¦ ë°ì´í„°: {len(datamodule.val_dataset)} videos")
        
        # ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸
        train_loader = datamodule.train_dataloader()
        val_loader = datamodule.val_dataloader()
        
        print(f"   âœ… í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"   âœ… ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ ë¡œë”© í…ŒìŠ¤íŠ¸
        print("   ğŸ”„ ì²« ë²ˆì§¸ ë°°ì¹˜ ë¡œë”© ì¤‘...")
        batch = next(iter(train_loader))
        
        video = batch["video"]
        label = batch["label"]
        
        print(f"   âœ… ë¹„ë””ì˜¤ í…ì„œ í¬ê¸°: {video.shape}")
        print(f"   âœ… ë¼ë²¨ ê°œìˆ˜: {len(label)}")
        print(f"   âœ… ë¼ë²¨ ì˜ˆì‹œ: {label}")
        
        return datamodule, batch
        
    except Exception as e:
        print(f"   âŒ ë°ì´í„° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


def test_model(num_classes: int, batch: dict, model_name: str = "x3d_s"):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ¤– ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘... (ëª¨ë¸: {model_name})")
    
    try:
        # ëª¨ë¸ ìƒì„±
        model = SignLanguageClassifier(
            num_classes=num_classes,
            model_name=model_name,
            learning_rate=1e-3,
            pretrained=False,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¹„í™œì„±í™” (ë¹ ë¥¸ ë¡œë”©)
        )
        
        print(f"   âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print(f"   âœ… íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
        
        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        model.eval()
        
        # ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
        print("   ğŸ”„ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ ì¤‘...")
        video = batch["video"]
        
        with torch.no_grad():
            logits = model(video)
        
        print(f"   âœ… ì¶œë ¥ í¬ê¸°: {logits.shape}")
        print(f"   âœ… ì˜ˆìƒ ì¶œë ¥ í¬ê¸°: ({video.shape[0]}, {num_classes})")
        
        # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        predictions = torch.argmax(logits, dim=1)
        probabilities = torch.softmax(logits, dim=1)
        
        print(f"   âœ… ì˜ˆì¸¡ ì¸ë±ìŠ¤: {predictions.tolist()}")
        print(f"   âœ… ìµœëŒ€ í™•ë¥ : {probabilities.max(dim=1)[0].tolist()}")
        
        return model
        
    except Exception as e:
        print(f"   âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


def test_training_step(model, batch, datamodule):
    """í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸"""
    print("\nğŸƒ í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        model.train()
        
        # ë”ë¯¸ íŠ¸ë ˆì´ë„ˆ ì„¤ì • (datamodule ì ‘ê·¼ì„ ìœ„í•´)
        class DummyTrainer:
            def __init__(self, datamodule):
                self.datamodule = datamodule
        
        model.trainer = DummyTrainer(datamodule)
        
        # í•™ìŠµ ìŠ¤í… ì‹¤í–‰
        loss = model.training_step(batch, 0)
        
        print(f"   âœ… ì†ì‹¤ê°’: {loss.item():.4f}")
        print(f"   âœ… ì†ì‹¤ í…ì„œ í¬ê¸°: {loss.shape}")
        
        # ê²€ì¦ ìŠ¤í… ì‹¤í–‰
        model.eval()
        with torch.no_grad():
            val_loss = model.validation_step(batch, 0)
        
        print(f"   âœ… ê²€ì¦ ì†ì‹¤ê°’: {val_loss.item():.4f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ìˆ˜ì–´ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--data_root", type=str, required=True,
                       help="ë°ì´í„° ë£¨íŠ¸ í´ë” ê²½ë¡œ")
    parser.add_argument("--model_name", type=str, default="x3d_s",
                       choices=["slow_r50", "x3d_s", "x3d_m", "mvit_base_16x4", "efficient_x3d_xs", "efficient_x3d_s"],
                       help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸")
    parser.add_argument("--batch_size", type=int, default=2,
                       help="í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸°")
    
    args = parser.parse_args()
    
    print("ğŸš€ ìˆ˜ì–´ ë¶„ë¥˜ ì‹œìŠ¤í…œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {args.data_root}")
    print(f"ğŸ¯ ëª¨ë¸: {args.model_name}")
    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    
    # ë°ì´í„° ì¡´ì¬ í™•ì¸
    data_path = Path(args.data_root)
    if not data_path.exists():
        print(f"âŒ ë°ì´í„° ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.data_root}")
        return
    
    video_dir = data_path / "video"
    label_dir = data_path / "label"
    
    if not video_dir.exists():
        print(f"âŒ ë¹„ë””ì˜¤ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_dir}")
        return
        
    if not label_dir.exists():
        print(f"âŒ ë¼ë²¨ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {label_dir}")
        return
    
    print(f"âœ… ë°ì´í„° ê²½ë¡œ í™•ì¸ ì™„ë£Œ")
    
    try:
        # 1. ë°ì´í„° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        datamodule, batch = test_datamodule(args.data_root, args.batch_size)
        
        # 2. ëª¨ë¸ í…ŒìŠ¤íŠ¸
        model = test_model(datamodule.num_classes, batch, args.model_name)
        
        # 3. í•™ìŠµ ìŠ¤í… í…ŒìŠ¤íŠ¸
        test_training_step(model, batch, datamodule)
        
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("\nğŸ“‹ ìš”ì•½:")
        print(f"   â€¢ ë°ì´í„°ì…‹: {len(datamodule.train_dataset)} í•™ìŠµ + {len(datamodule.val_dataset)} ê²€ì¦")
        print(f"   â€¢ í´ë˜ìŠ¤ ìˆ˜: {datamodule.num_classes}")
        print(f"   â€¢ ëª¨ë¸: {args.model_name}")
        print(f"   â€¢ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
        
        print("\nğŸš€ ì´ì œ ë³¸ê²©ì ì¸ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”:")
        print(f"python train_sign_language.py --data_root {args.data_root} --model_name {args.model_name} --batch_size {args.batch_size} --epochs 10 --fast_dev_run")
        
    except Exception as e:
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("2. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš” (pip install -r requirements.txt)")
        print("3. GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ --batch_sizeë¥¼ ì¤„ì—¬ë³´ì„¸ìš”")
        print("4. ë¹„ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 